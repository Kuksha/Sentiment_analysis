{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score ,StratifiedKFold,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"products_sentiment_train.tsv\", sep = \"\\t\", header = None, names = [\"text\", \"label\"])\n",
    "test =  pd.read_csv(\"products_sentiment_test.tsv\", sep = \"\\t\", index_col = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0          2 . take around 10,000 640x480 pictures .      1\n",
       "1  i downloaded a trial version of computer assoc...      1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...      1\n",
       "3  i dont especially like how music files are uns...      0\n",
       "4  i was using the cheapie pail ... and it worked...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2 . take around 10,000 640x480 pictures .',\n",
       "       'i downloaded a trial version of computer associates ez firewall and antivirus and fell in love with a computer security system all over again .',\n",
       "       'the wrt54g plus the hga7t is a perfect solution if you need wireless coverage in a wider area or for a hard-walled house as was my case .',\n",
       "       ..., 'overall i like it . ',\n",
       "       'i began taking pics as soon as i got this camera and am amazed at the quality of photos i have took simply by using the auto mode . ',\n",
       "       \"even after reading some of the instructions , it 's still hard to figure out . \"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "negfeats =  list(train[train.label == 0][\"text\"].values)\n",
    "posfeats =  list(train[train.label == 1][\"text\"].values)\n",
    "texts = train.text.values\n",
    "y = train.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2 . take around 10,000 640x480 pictures .',\n",
       "       'i downloaded a trial version of computer associates ez firewall and antivirus and fell in love with a computer security system all over again .',\n",
       "       'the wrt54g plus the hga7t is a perfect solution if you need wireless coverage in a wider area or for a hard-walled house as was my case .',\n",
       "       ..., 'overall i like it . ',\n",
       "       'i began taking pics as soon as i got this camera and am amazed at the quality of photos i have took simply by using the auto mode . ',\n",
       "       \"even after reading some of the instructions , it 's still hard to figure out . \"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274\n",
      "726\n"
     ]
    }
   ],
   "source": [
    "print(len(posfeats))\n",
    "print(len(negfeats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовое решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(vectorizer, transformer, classifier):\n",
    "    return Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('transformer', transformer),\n",
    "            ('classifier', classifier)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7655000000000001\n"
     ]
    }
   ],
   "source": [
    "pipe_base = make_pipeline(CountVectorizer(), TfidfTransformer(),LogisticRegression(solver = \"liblinear\"))\n",
    "result_base = cross_val_score(pipe_base, texts, y, cv =5, scoring=\"accuracy\")\n",
    "print(result_base.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор оптимального решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейные классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression :  0.766\n",
      "LinearSVC :  0.7689999999999999\n",
      "SGDClassifier :  0.7545\n"
     ]
    }
   ],
   "source": [
    "for name, clf in [('LogisticRegression', LogisticRegression), \n",
    "                  ('LinearSVC', LinearSVC), \n",
    "                  ('SGDClassifier', SGDClassifier)]:\n",
    "    score = cross_val_score(make_pipeline(CountVectorizer(), TfidfTransformer(), clf(random_state=12)), texts, y, cv=5).mean()\n",
    "    print(name,\": \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_estimator(classifier, params_grid, data, labels):\n",
    "    pipeline = make_pipeline(CountVectorizer(), TfidfTransformer(), classifier)\n",
    "    grid_cv = RandomizedSearchCV(pipeline, params_grid, scoring='accuracy', cv=5, random_state=12, n_iter=100,n_jobs=-1)\n",
    "    grid_cv.fit(data, labels)\n",
    "    return grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсметры для каждой модели\n",
    "\n",
    "params_grid_lr = {\n",
    "    'classifier__C': np.arange(0.1, 2, 0.1),\n",
    "    'classifier__max_iter': np.arange(50, 500, 50),\n",
    "    'classifier__solver': ['lbfgs', 'liblinear', 'sag']\n",
    "}\n",
    "params_grid_lsvc = {\n",
    "    'classifier__loss': ['hinge', 'squared_hinge'], \n",
    "    'classifier__max_iter': np.arange(100, 1000, 50),\n",
    "    'classifier__tol': [1e-5, 1e-4, 1e-3],\n",
    "    'classifier__C': np.arange(0.1, 2, 0.1)\n",
    "}\n",
    "params_grid_sgdc = {\n",
    "    'classifier__loss': ['log', 'hinge', 'modified_huber'], \n",
    "    'classifier__penalty':  ['l1', 'l2', 'elasticnet'], \n",
    "    'classifier__max_iter': np.arange(100, 1000, 50),\n",
    "    'classifier__tol': np.arange(1e-5, 1e-3, 1e-5),\n",
    "}\n",
    "\n",
    "\n",
    "params_grid_vectorizer = {\n",
    "    'vectorizer__max_df' : [0.85, 0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df' : [1, 10, 20], \n",
    "    'vectorizer__ngram_range' : [(1, x) for x in range(1,7)],\n",
    "    'vectorizer__stop_words' : [ None, 'english']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.7585\n",
      "Wall time: 38.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_lr = make_estimator(LogisticRegression(), \n",
    "                                {**params_grid_vectorizer, **params_grid_lr}, texts, y)\n",
    "print(\"LogisticRegression: %.4f\" % grid_search_lr.best_score_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC: 0.7905\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "grid_search_lsvc = make_estimator(LinearSVC(random_state=12), \n",
    "                                  {**params_grid_vectorizer, **params_grid_lsvc}, texts, y)\n",
    "print(\"LinearSVC: %.4f\" % grid_search_lsvc.best_score_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier: 0.7920\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "grid_search_sgdc = make_estimator(SGDClassifier(random_state=12), \n",
    "                                  {**params_grid_vectorizer, **params_grid_sgdc},  texts, y)\n",
    "print(\"SGDClassifier: %.4f\" % grid_search_sgdc.best_score_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая линейная модель: SGDClassifier, Accuracy = 0.7920\n",
      "Параметры модели: SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=200, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=12, shuffle=True, tol=0.00093,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Парамтры предобработки: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=0.85, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 4), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Лучшая линейная модель: SGDClassifier, Accuracy = %.4f\"% grid_search_sgdc.best_score_)\n",
    "print(\"Параметры модели:\",  grid_search_sgdc.best_estimator_[2])\n",
    "print(\"Парамтры предобработки:\", grid_search_sgdc.best_estimator_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нелинейные алгоритмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, clf in [('GradientBoostingClassifier', GradientBoostingClassifier), \n",
    "                  ('RandomForestClassifier', RandomForestClassifier)]:\n",
    "    score = cross_val_score(make_pipeline(CountVectorizer(), TfidfTransformer(), clf(max_depth = 10,random_state=12)), texts, y, cv=5).mean()\n",
    "    print(name,\": \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_grid_gbt = {\n",
    "    \"classifier__learning_rate\": [0.01, 0.05,0.1, 0.15, 0.2],\n",
    "    \"classifier__min_samples_split\": np.linspace(0.05, 0.25, 5),\n",
    "    \"classifier__max_depth\":[3,5,8, 12],\n",
    "    \"classifier__max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"classifier__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"classifier__n_estimators\": np.arange(100, 1000,100)\n",
    "}\n",
    "params_grid_rf = {\n",
    "    'classifier__n_estimators':np.arange(100, 1000,100),\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__max_depth': np.arange(2,16,2),\n",
    "    'classifier__criterion': ['gini', 'entropy'],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search_gbt = make_estimator(GradientBoostingClassifier(random_state=12), \n",
    "                                {**params_grid_vectorizer, **params_grid_gbt}, texts, y)\n",
    "print(\"GradientBoostingClassifier: %.4f\" % grid_search_gbt.best_score_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search_rf = make_estimator(RandomForestClassifier(), \n",
    "                                {**params_grid_vectorizer, **params_grid_rf}, texts, y)\n",
    "print(\"RandomForestClassifier: %.4f\" % grid_search_rf.best_score_ )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем генерацию новых признаков с помощью метода главных компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x74561 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 114831 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TfidfTransformer().fit_transform(CountVectorizer(ngram_range=(1,4)).fit_transform(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_estimator(classifier, params_grid, data, labels):\n",
    "    pipeline =     Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('transformer', TfidfTransformer()),\n",
    "            (\"pca\", TruncatedSVD()),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "    grid_cv = RandomizedSearchCV(pipeline, params_grid, scoring='accuracy', cv=5, random_state=12, n_iter=100,n_jobs=-1, verbose =10)\n",
    "    grid_cv.fit(data, labels)\n",
    "    return grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_grid = {\n",
    "    \"pca__n_components\" : [100, 250, 500,1000,2000,5000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LinearSVC: %.4f\" % grid_search_lsvc.best_estimator_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_grid_lsvc = {\n",
    "    'classifier__loss': ['hinge', 'squared_hinge'], \n",
    "    'classifier__max_iter': np.arange(100, 600, 100),\n",
    "    'classifier__tol': [1e-5, 1e-4, 1e-3],\n",
    "    'classifier__C': np.arange(0.1, 2, 0.1)\n",
    "}\n",
    "params_grid_sgdc = {\n",
    "    'classifier__loss': ['log', 'hinge', 'modified_huber'], \n",
    "    'classifier__penalty':  ['l1', 'l2', 'elasticnet'], \n",
    "    'classifier__max_iter': np.arange(100, 500, 100),\n",
    "    'classifier__tol': np.arange(1e-5, 1e-3, 1e-5),\n",
    "}\n",
    "\n",
    "\n",
    "params_grid_vectorizer = {\n",
    "    'vectorizer__max_df' : [0.85, 0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df' : [1, 10, 20], \n",
    "    'vectorizer__ngram_range' : [(1, x) for x in range(1,6)],\n",
    "    'vectorizer__stop_words' : [ None, 'english']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_lsvc = make_estimator(LinearSVC(random_state=12), \n",
    "                                  {**params_grid_vectorizer, **params_grid_lsvc, **pca_grid}, texts, y)\n",
    "print(\"LinearSVC: %.4f\" % grid_search_lsvc.best_score_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоговая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = grid_search_sgdc.best_estimator_.predict(test.text.values)\n",
    "df = pd.Series(arr).to_frame()\n",
    "df.columns = [ \"y\"]\n",
    "df.index.name = \"Id\"\n",
    "df.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
